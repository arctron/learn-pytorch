{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKyxbaNigOTLaP4W5sn9KC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arctron/learn-pytorch/blob/main/Regression_In_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "- https://www.learnpytorch.io/01_pytorch_workflow/"
      ],
      "metadata": {
        "id": "pwGpZOEreblg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "62VRQj-HdxpH",
        "outputId": "89c3af6b-fab2-422d-cdb3-3476c718b8c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "x = torch.arange(1, 10, 1).type(torch.float)\n",
        "print(x.shape, x.device, x.dtype)\n",
        "m = 0.5\n",
        "c = 3\n",
        "y = m * x + c\n",
        "\n",
        "split = int(0.8 * len(x))\n",
        "x_train, y_train = x[:split], y[:split]\n",
        "x_test, y_test = x[split:], y[split:]\n",
        "x_train = x_train.unsqueeze(0)\n",
        "y_train = y_train.unsqueeze(0)\n",
        "x_test = x_test.unsqueeze(0)\n",
        "y_test = y_test.unsqueeze(0)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "\n",
        "# Random initlization of parameters\n",
        "w = torch.rand((1, 1), requires_grad = True)\n",
        "b = torch.rand((1, 1), requires_grad = True)\n",
        "\n",
        "print('----------------')\n",
        "\n",
        "print('w is', w, w.shape)\n",
        "print('b is', b, b.shape)\n",
        "\n",
        "print('------ x train is ------')\n",
        "print(x_train)\n",
        "\n",
        "print('------ y train is ------')\n",
        "print(y_train)\n",
        "\n",
        "# Gradient Descent\n",
        "for i in range(500):\n",
        "  # Forward pass\n",
        "  o = w @ x_train + b\n",
        "  # print('o is ')\n",
        "  # print(o)\n",
        "\n",
        "  # Loss\n",
        "  loss = ((o - y_train) ** 2).sum()\n",
        "  # print('loss is')\n",
        "  # print(o - y_train)\n",
        "  # print((o - y_train) ** 2)\n",
        "  # print('***** Loss value is : ***** = ', loss)\n",
        "\n",
        "  # Zero out gradients\n",
        "  w.grad = None\n",
        "  b.grad = None\n",
        "\n",
        "  # Backprop\n",
        "  loss.backward()\n",
        "\n",
        "  # print(f'{w.grad=}, {b.grad=}')\n",
        "  w.data -= 0.005 * w.grad\n",
        "  b.data -= 0.005 * b.grad\n",
        "\n",
        "\n",
        "print(w, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2T_eKsletDS",
        "outputId": "8054eef3-04e3-4787-cd37-6abc97896fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9]) cpu torch.float32\n",
            "torch.Size([1, 7]) torch.Size([1, 7])\n",
            "torch.Size([1, 2]) torch.Size([1, 2])\n",
            "----------------\n",
            "w is tensor([[0.6449]], requires_grad=True) torch.Size([1, 1])\n",
            "b is tensor([[0.5739]], requires_grad=True) torch.Size([1, 1])\n",
            "------ x train is ------\n",
            "tensor([[1., 2., 3., 4., 5., 6., 7.]])\n",
            "------ y train is ------\n",
            "tensor([[3.5000, 4.0000, 4.5000, 5.0000, 5.5000, 6.0000, 6.5000]])\n",
            "tensor([[0.5005]], requires_grad=True) tensor([[2.9973]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LR(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.rand(1, dtype=torch.float, requires_grad=True))\n",
        "    self.bias = nn.Parameter(torch.rand(1, dtype=torch.float, requires_grad=True))\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return self.weights * x + self.bias\n"
      ],
      "metadata": {
        "id": "yk3c_kQbh5Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model = LR()\n",
        "print(list(model.parameters()))\n",
        "print(model.state_dict())\n",
        "\n",
        "loss_fn = nn.L1Loss() # MAE\n",
        "\n",
        "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, 'min')\n",
        "\n",
        "for i in range(1000):\n",
        "  model.train()\n",
        "  y_pred = model(x_train)\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "  scheduler.step(loss)\n",
        "  if i % 50 == 0:\n",
        "    print(i, loss, model.state_dict())\n",
        "\n",
        "print('Final:', loss, model.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SP6q10ifxJJ",
        "outputId": "1c5c86e2-1c86-45c9-dde3-52fb0136d9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([0.8823], requires_grad=True), Parameter containing:\n",
            "tensor([0.9150], requires_grad=True)]\n",
            "OrderedDict([('weights', tensor([0.8823])), ('bias', tensor([0.9150]))])\n",
            "0 tensor(0.7843, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.8851])), ('bias', tensor([0.9193]))])\n",
            "50 tensor(0.7082, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.8708])), ('bias', tensor([1.1021]))])\n",
            "100 tensor(0.6411, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.8423])), ('bias', tensor([1.2821]))])\n",
            "150 tensor(0.5756, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.7994])), ('bias', tensor([1.4593]))])\n",
            "200 tensor(0.5084, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.7708])), ('bias', tensor([1.6393]))])\n",
            "250 tensor(0.4429, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.7280])), ('bias', tensor([1.8164]))])\n",
            "300 tensor(0.3758, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.6994])), ('bias', tensor([1.9964]))])\n",
            "350 tensor(0.3102, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.6566])), ('bias', tensor([2.1736]))])\n",
            "400 tensor(0.2431, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.6280])), ('bias', tensor([2.3536]))])\n",
            "450 tensor(0.1776, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5851])), ('bias', tensor([2.5307]))])\n",
            "500 tensor(0.1105, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5566])), ('bias', tensor([2.7107]))])\n",
            "550 tensor(0.0616, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5594])), ('bias', tensor([2.8707]))])\n",
            "600 tensor(0.1384, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5051])), ('bias', tensor([2.9479]))])\n",
            "650 tensor(0.0135, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5063])), ('bias', tensor([2.9650]))])\n",
            "700 tensor(0.0083, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5066])), ('bias', tensor([2.9825]))])\n",
            "750 tensor(0.0075, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5040])), ('bias', tensor([2.9936]))])\n",
            "800 tensor(0.0016, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5008])), ('bias', tensor([2.9958]))])\n",
            "850 tensor(0.0009, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5004])), ('bias', tensor([2.9976]))])\n",
            "900 tensor(0.0005, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5005])), ('bias', tensor([2.9991]))])\n",
            "950 tensor(0.0002, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5001])), ('bias', tensor([2.9996]))])\n",
            "Final: tensor(9.5470e-05, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([0.5001])), ('bias', tensor([2.9997]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(x: torch.Tensor) -> torch.Tensor:\n",
        "  maxv, i = torch.max(x, dim=0, keepdim=True)\n",
        "  minv, i = torch.min(x, dim=0, keepdim=True)\n",
        "  return ((x - minv)/(maxv - minv)), maxv, minv"
      ],
      "metadata": {
        "id": "eA67PApMl_eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quadratic Regression\n",
        "a = 3\n",
        "b = 5\n",
        "c = 19\n",
        "x = torch.arange(0, 20, 0.4).unsqueeze(dim=1)\n",
        "y = a*x*x + b*x + c\n",
        "\n",
        "\n",
        "split = int(0.8 * len(x))\n",
        "x_train, y_train = x[:split], y[:split]\n",
        "x_test, y_test = x[split:], y[split:]\n",
        "x_train = torch.stack((x_train.squeeze(1) * x_train.squeeze(1), x_train.squeeze(1)), dim=1)\n",
        "x_test = torch.stack((x_test.squeeze(1) * x_test.squeeze(1), x_test.squeeze(1)), dim=1)\n",
        "\n",
        "x_train, max_x_train, min_x_train = normalize(x_train)\n",
        "y_train, max_y_train, min_y_train = normalize(y_train)\n",
        "x_test = ((x_test - min_x_train)/(max_x_train - min_x_train))\n",
        "y_test = ((y_test - min_y_train)/(max_y_train - min_y_train))\n",
        "\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxNGzmYl_Bfk",
        "outputId": "2b556581-6efc-4be0-8a04-12e466d885e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40, 2]) torch.Size([40, 1])\n",
            "torch.Size([10, 2]) torch.Size([10, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QR(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.rand((2, 1), dtype=torch.float, requires_grad=True))\n",
        "    self.bias = nn.Parameter(torch.rand((1, 1), dtype=torch.float, requires_grad=True))\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return x @ self.weights + self.bias\n"
      ],
      "metadata": {
        "id": "2mFqeBaT_ty8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.manual_seed(42)\n",
        "\n",
        "model = QR()\n",
        "print(list(model.parameters()))\n",
        "print(model.state_dict())\n",
        "\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "optim = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, 'min')\n",
        "\n",
        "for i in range(3000):\n",
        "  model.train()\n",
        "  y_pred = model(x_train)\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  optim.zero_grad()\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "  scheduler.step(loss)\n",
        "\n",
        "  if i % 100 == 0:\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "      test_pred = model(x_test)\n",
        "      test_loss = loss_fn(test_pred, y_test)\n",
        "      print(f'{i}: Train Loss: {loss.data}, Test Loss: {test_loss.data}')\n",
        "\n",
        "print('Final:', loss, model.state_dict())\n",
        "print(model.state_dict()['weights'])\n",
        "print(model.state_dict()['bias'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTwg2evhG7Qm",
        "outputId": "21ba129e-3d5c-4dcd-93ed-071471e3d177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5472],\n",
            "        [0.0062]], requires_grad=True), Parameter containing:\n",
            "tensor([[0.9516]], requires_grad=True)]\n",
            "OrderedDict([('weights', tensor([[0.5472],\n",
            "        [0.0062]])), ('bias', tensor([[0.9516]]))])\n",
            "0: Train Loss: 0.7860885262489319, Test Loss: 0.3625355064868927\n",
            "100: Train Loss: 0.18557517230510712, Test Loss: 0.5095734000205994\n",
            "200: Train Loss: 0.08603464066982269, Test Loss: 0.2631135880947113\n",
            "300: Train Loss: 0.009158364497125149, Test Loss: 0.0025018095038831234\n",
            "400: Train Loss: 0.0017788481200113893, Test Loss: 0.008579504676163197\n",
            "500: Train Loss: 0.0015676359180361032, Test Loss: 0.007017242722213268\n",
            "600: Train Loss: 0.0013636210933327675, Test Loss: 0.006144237704575062\n",
            "700: Train Loss: 0.0011612974340096116, Test Loss: 0.005336451344192028\n",
            "800: Train Loss: 0.0009566668304614723, Test Loss: 0.004255437757819891\n",
            "900: Train Loss: 0.0007546780980192125, Test Loss: 0.0033823014236986637\n",
            "1000: Train Loss: 0.0005525198648683727, Test Loss: 0.0025091408751904964\n",
            "1100: Train Loss: 0.00036005256697535515, Test Loss: 0.0017249106895178556\n",
            "1200: Train Loss: 0.0003119774628430605, Test Loss: 0.0015187740791589022\n",
            "1300: Train Loss: 0.00029028920107521117, Test Loss: 0.001315808272920549\n",
            "1400: Train Loss: 0.000269709707936272, Test Loss: 0.0012291192542761564\n",
            "1500: Train Loss: 0.00024947739439085126, Test Loss: 0.0011352419387549162\n",
            "1600: Train Loss: 0.00022901312331669033, Test Loss: 0.0010277151595801115\n",
            "1700: Train Loss: 0.00020892266184091568, Test Loss: 0.0009477734565734863\n",
            "1800: Train Loss: 0.00018859421834349632, Test Loss: 0.000854194164276123\n",
            "1900: Train Loss: 0.0001680424902588129, Test Loss: 0.000753509986680001\n",
            "2000: Train Loss: 0.0001476094766985625, Test Loss: 0.0006668090936727822\n",
            "2100: Train Loss: 0.0001274178794119507, Test Loss: 0.0005729437107220292\n",
            "2200: Train Loss: 0.00010697289690142497, Test Loss: 0.000492906547151506\n",
            "2300: Train Loss: 8.65738038555719e-05, Test Loss: 0.00039217472658492625\n",
            "2400: Train Loss: 6.620936619583517e-05, Test Loss: 0.0002986788749694824\n",
            "2500: Train Loss: 4.583586996886879e-05, Test Loss: 0.0002119064301950857\n",
            "2600: Train Loss: 3.297918738098815e-05, Test Loss: 0.0001646280288696289\n",
            "2700: Train Loss: 3.068174555664882e-05, Test Loss: 0.00013968945131637156\n",
            "2800: Train Loss: 2.863702866306994e-05, Test Loss: 0.00012915134720969945\n",
            "2900: Train Loss: 2.662341285031289e-05, Test Loss: 0.00012036562111461535\n",
            "Final: tensor(2.4651e-05, grad_fn=<MeanBackward0>) OrderedDict([('weights', tensor([[0.9031],\n",
            "        [0.0969]])), ('bias', tensor([[-8.2288e-05]]))])\n",
            "tensor([[0.9031],\n",
            "        [0.0969]])\n",
            "tensor([[-8.2288e-05]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = (max_y_train - min_y_train).item()\n",
        "v2 = (max_x_train - min_x_train)[0][0].item()\n",
        "v3 = (max_x_train - min_x_train)[0][1].item()\n",
        "w1 = model.state_dict()['weights'][0].item()\n",
        "w2 = model.state_dict()['weights'][1].item()\n",
        "bias = model.state_dict()['bias'].item()\n",
        "minx2 = min_x_train[0][0].item()\n",
        "minx = min_x_train[0][1].item()\n",
        "miny = min_y_train.item()\n",
        "# print(v1, v2, v3)\n",
        "# print(w1, w2, bias)\n",
        "print('---Predicted coefficients---')\n",
        "print('a = ', w1 * v1/v2)\n",
        "print('b = ', w2 * v1/v3)\n",
        "print('c = ',bias + miny  - (v1/v2 * w1 * minx2) - (v1/v3 * w2 * minx))\n",
        "print('----------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI_u6LUe7JEV",
        "outputId": "09d49c9c-e1d8-4b55-e285-be58834129c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Predicted coefficients---\n",
            "a =  2.9987809975192397\n",
            "b =  5.020471337950935\n",
            "c =  18.999917711778835\n",
            "----------------------------\n"
          ]
        }
      ]
    }
  ]
}